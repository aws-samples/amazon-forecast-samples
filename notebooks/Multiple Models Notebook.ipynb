{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple models comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will run three forecasting algorithms on the same dataset and compare their performances.\n",
    "\n",
    "The algorithms are:\n",
    "  - Prophet\n",
    "  - ETS\n",
    "  - DeepAR+\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=2)  # Better display for dictionaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The line below will retrieve your shared variables from the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last part of the setup process is to validate that your account can communicate with Amazon Forecast, the cell below does just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = boto3.client(service_name='forecast')\n",
    "forecastquery = boto3.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to create a dictionary where to store useful information about the algorithms: their name, ARN and eventually their performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = ['Prophet', 'ETS', 'Deep_AR_Plus']\n",
    "\n",
    "predictors = {a:{} for a in algos}\n",
    "\n",
    "for p in predictors:\n",
    "    predictors[p]['predictor_name'] = project + '_' + p + '_algo'\n",
    "    predictors[p]['algorithm_arn'] = 'arn:aws:forecast:::algorithm/' + p\n",
    "\n",
    "pp.pprint(predictors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we also define our forecast horizon: the number of time points to be predicted in the future. For weekly data, a value of 12 means 12 weeks. Our example is hourly data, we try forecast the next day, so we can set to 24."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastHorizon = 24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function actually creates the predictor as specified by several parameters. We will call this function once for each of the 3 algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predictor_response(pred_name, algo_arn, forecast_horizon):\n",
    "    response=forecast.create_predictor(PredictorName=pred_name, \n",
    "                                       AlgorithmArn=algo_arn,\n",
    "                                       ForecastHorizon=forecast_horizon,\n",
    "                                       PerformAutoML= False,\n",
    "                                       PerformHPO=False,\n",
    "                                       EvaluationParameters= {\"NumberOfBacktestWindows\": 1, \n",
    "                                                              \"BackTestWindowOffset\": 24}, \n",
    "                                       InputDataConfig= {\"DatasetGroupArn\": datasetGroupArn},\n",
    "                                       FeaturizationConfig= {\"ForecastFrequency\": \"H\", \n",
    "                                                             \"Featurizations\": \n",
    "                                                             [\n",
    "                                                                 {\"AttributeName\": \"target_value\", \n",
    "                                                                  \"FeaturizationPipeline\": \n",
    "                                                                  [\n",
    "                                                                      {\"FeaturizationMethodName\": \"filling\", \n",
    "                                                                       \"FeaturizationMethodParameters\": \n",
    "                                                                       {\"frontfill\": \"none\", \n",
    "                                                                        \"middlefill\": \"zero\", \n",
    "                                                                        \"backfill\": \"zero\"}\n",
    "                                                                      }\n",
    "                                                                  ]\n",
    "                                                                 }\n",
    "                                                             ]\n",
    "                                                            }\n",
    "                                      )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all 3 algorithms, we invoke their creation and wait until they are complete. We also store their performance in our dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in predictors.keys():\n",
    "    predictor_response = create_predictor_response(predictors[p]['predictor_name'], predictors[p]['algorithm_arn'], forecastHorizon)\n",
    "    \n",
    "    predictorArn=predictor_response['PredictorArn']\n",
    "    \n",
    "    # wait for the predictor to be actually created\n",
    "    print('------------------ Creating ' + p)\n",
    "    while True:\n",
    "        predictorStatus = forecast.describe_predictor(PredictorArn=predictorArn)['Status']\n",
    "        print(predictorStatus)\n",
    "        if predictorStatus != 'ACTIVE' and predictorStatus != 'CREATE_FAILED':\n",
    "            sleep(30)\n",
    "        else:\n",
    "            predictors[p]['predictor_arn'] = predictorArn  # save it, just for reference\n",
    "            break\n",
    "            \n",
    "    # compute and store performance metrics, then proceed with the next algorithm        \n",
    "    predictors[p]['accuracy'] = forecast.get_accuracy_metrics(PredictorArn=predictorArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO:** (Bar?)plot RMSE, 0.9-, 0.5- and 0.1-quantile LossValues for each algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what we stored so far for DeepAR+:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.pprint(predictors['Deep_AR_Plus'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `seaborn` as it interacts well with `pandas` DataFrames."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looping over our dictionary, we can retrieve the Root Mean Square Error (RMSE) for each predictor and plot it as a bar plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.DataFrame(columns=['predictor', 'RMSE'])\n",
    "for p in predictors:\n",
    "    score = predictors[p]['accuracy']['PredictorEvaluationResults'][0]['TestWindows'][0]['Metrics']['RMSE']\n",
    "    scores = scores.append(pd.DataFrame({'predictor':[p], 'RMSE':[score]}), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = sns.barplot(data=scores, x='predictor', y='RMSE').set_title('Root Mean Square Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
